// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 6.0 effective-5.10 (swiftlang-6.0.0.9.10 clang-1600.0.26.2)
// swift-module-flags: -target x86_64-apple-ios15.0-simulator -enable-objc-interop -enable-library-evolution -enforce-exclusivity=checked -O -enable-experimental-feature AccessLevelOnImport -enable-bare-slash-regex -module-name MediaPipeTasksGenAI -package-name third_party/mediapipe/tasks/ios/genai/inference
// swift-module-flags-ignorable: -no-verify-emitted-module-interface
import CoreGraphics
import Foundation
import MediaPipeTasksGenAIC
import Swift
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
@objc(MPPLLMInference) final public class LlmInference : ObjectiveC.NSObject {
  final public var metrics: MediaPipeTasksGenAI.LlmInference.Metrics {
    get
  }
  @objc public init(options: MediaPipeTasksGenAI.LlmInference.Options) throws
  @objc convenience public init(modelPath: Swift.String) throws
  @objc final public func generateResponse(inputText: Swift.String) throws -> Swift.String
  @objc final public func generateResponseAsync(inputText: Swift.String, progress: @escaping (_ partialResponse: Swift.String?, _ error: (any Swift.Error)?) -> Swift.Void, completion: @escaping (() -> Swift.Void)) throws
  @available(iOS 13, macOS 10.15, tvOS 13, watchOS 6, *)
  final public func generateResponseAsync(inputText: Swift.String) -> _Concurrency.AsyncThrowingStream<Swift.String, any Swift.Error>
  @objc deinit
}
extension MediaPipeTasksGenAI.LlmInference {
  @objc(MPPLLMInferenceOptions) final public class Options : ObjectiveC.NSObject {
    @objc final public var modelPath: Swift.String
    @objc final public var visionEncoderPath: Swift.String
    @objc final public var visionAdapterPath: Swift.String
    @objc final public var maxTokens: Swift.Int
    @objc final public var maxImages: Swift.Int
    @objc final public var maxTopk: Swift.Int
    @objc final public var supportedLoraRanks: [Swift.Int]
    @objc final public var waitForWeightUploads: Swift.Bool
    @objc final public var useSubmodel: Swift.Bool
    @objc final public var sequenceBatchSize: Swift.Int
    @objc public init(modelPath: Swift.String)
    @objc deinit
  }
}
extension MediaPipeTasksGenAI.LlmInference {
  @objc(MPPLLMInferenceMetrics) final public class Metrics : ObjectiveC.NSObject {
    @objc final public let initializationTimeInSeconds: Foundation.TimeInterval
    @objc public init(initializationTimeInSeconds: Foundation.TimeInterval)
    @objc deinit
  }
}
extension MediaPipeTasksGenAI.LlmInference {
  @_hasMissingDesignatedInitializers @objc(MPPLLMInferenceSession) final public class Session : ObjectiveC.NSObject {
    final public var metrics: MediaPipeTasksGenAI.LlmInference.Session.Metrics {
      get
    }
    @objc public init(llmInference: MediaPipeTasksGenAI.LlmInference, options: MediaPipeTasksGenAI.LlmInference.Session.Options) throws
    @objc convenience public init(llmInference: MediaPipeTasksGenAI.LlmInference) throws
    @objc final public func addQueryChunk(inputText: Swift.String) throws
    @objc final public func addImage(image: CoreGraphics.CGImage) throws
    @objc final public func generateResponse() throws -> Swift.String
    @objc final public func generateResponseAsync(progress: @escaping (_ partialResponse: Swift.String?, _ error: (any Swift.Error)?) -> Swift.Void, completion: @escaping (() -> Swift.Void)) throws
    @available(iOS 13, macOS 10.15, tvOS 13, watchOS 6, *)
    final public func generateResponseAsync() -> _Concurrency.AsyncThrowingStream<Swift.String, any Swift.Error>
    final public func sizeInTokens(text: Swift.String) throws -> Swift.Int
    final public func clone() throws -> MediaPipeTasksGenAI.LlmInference.Session
    @objc deinit
  }
}
extension MediaPipeTasksGenAI.LlmInference.Session {
  @_inheritsConvenienceInitializers @objc(MPPLLMInferenceSessionOptions) final public class Options : ObjectiveC.NSObject {
    @objc final public var topk: Swift.Int
    @objc final public var topp: Swift.Float
    @objc final public var temperature: Swift.Float
    @objc final public var randomSeed: Swift.Int
    @objc final public var loraPath: Swift.String?
    @objc final public var enableVisionModality: Swift.Bool
    @objc override dynamic public init()
    @objc deinit
  }
}
extension MediaPipeTasksGenAI.LlmInference.Session {
  @objc(MPPLLMInferenceSessionMetrics) final public class Metrics : ObjectiveC.NSObject {
    @objc final public var responseGenerationTimeInSeconds: Foundation.TimeInterval {
      get
    }
    @objc public init(responseGenerationTimeInSeconds: Foundation.TimeInterval)
    @objc deinit
  }
}
public enum GenAiInferenceError : Swift.Error {
  case invalidResponse
  case illegalMethodCall
  case failedToComputeSizeInTokens(Swift.String?)
  case failedToInitializeSession(Swift.String?)
  case failedToInitializeEngine(Swift.String?)
  case failedToAddQueryToSession(Swift.String, Swift.String?)
  case failedToPredictSync(Swift.String?)
  case failedToPredictAsync(Swift.String?)
  case failedToCloneSession(Swift.String?)
}
extension MediaPipeTasksGenAI.GenAiInferenceError : Foundation.LocalizedError {
  public var errorDescription: Swift.String? {
    get
  }
}
extension MediaPipeTasksGenAI.GenAiInferenceError : Foundation.CustomNSError {
  public static var errorDomain: Swift.String {
    get
  }
  public var errorCode: Swift.Int {
    get
  }
}
